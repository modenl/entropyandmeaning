在为这本书写这篇前言时，我们正站在人类历史一个极不寻常的路口。

过去几百年的科技革命，本质上都是“工具更强了”：蒸汽机、电力、互联网、智能手机，让我们在同一片世界里跑得更快、协作得更高效，但“作为物种的人”并没有被根本动摇。
这一次不同。

AI 正在慢慢超出“工具”的范畴。不再只是某一类具体工作的替代者，而是在一点点替代人类在自然界中赖以生存的核心竞争优势——获取知识、理解世界、做出决策的能力。
知识的获取正变得几乎无限廉价，人类几千年文明史积累下来的大量经验，正在被 AI 重组和压缩。我们同时感到前所未有的期待和前所未有的不安：一方面，AI 带来的科技进步和社会福利可能远超以往任何一场革命；另一方面，我们也不得不追问一个从未如此尖锐的问题——在这样的前提下，“人”在进化树上的这一支，是否还具有独特而不可替代的存在意义？

如果把时间轴拉长，这场变革，归根到底是一场“智力的角逐”：
在 AGI 来临之前和之后，我们如何理解“智能”、如何使用“智能”、如何与更加高级的“智能”共存。

---

## 一、两个阶段的未来想象

为了梳理本书的逻辑，我们可以先给出一个粗略的时间框架，它未必精确，但有助于对问题形成直觉。

### 阶段一：AGI/ASI 早期阶段——人和工具的极限协作

假设在 2030–2035 年间，人类真正进入 AGI / ASI 的早期阶段，并在之后的几十年里持续演化。在这个阶段中，人和 AI 的形式关系仍然是“人—工具”，只是这个工具强大到前所未有。

在这段时期，我们大概率会看到：

* **几乎所有行业被持续重塑。**
  AI 像电力一样渗入每一个生产和服务环节，原有的分工体系被反复改写。竞争不再主要是“谁掌握更多知识”，而是“谁能更好地与 AI 协作”。

* **机器人和自动化系统释放出巨大的物质生产力。**
  生产环节中，机器人和智能系统可以 7×24 小时稳定工作，导致困扰人类几千年的“物质匮乏”和“资源竞争”问题在相当短的时间内被极大缓解。基本物质需求可以被高度、稳定地满足，大规模的饥饿和极端贫困不再是常态。

* **战争动力被削弱，疾病负担被显著降低。**
  当饥饿和极端生存压力大幅减少，大规模战争的传统动因会被削弱。与此同时，AI 赋能的生物医学会显著加速疾病机理研究和药物设计，大部分重大疾病的治疗方案会出现质变，人类预期寿命显著提高。

* **人机融合出现，但“人”仍然是主导者。**
  我们可能会看到神经接口、增强现实、外骨骼等形式的人机融合，AI 逐渐成为人类思维和肉身的“外挂”：帮我们思考、帮我们记忆、甚至部分接管我们的感官。但方向和边界仍然主要由人来设定。

* **基础科学和工程技术获得成倍加速。**
  当几乎每位科研工作者身后都有“AI 研究助手军团”时，基础科学上的突破会显著加快，大量过去认为“太复杂”的问题会被系统推进，工程落地周期大幅缩短。

从进化论与自然选择的视角看，在这一阶段比拼的是：**谁能更充分、更聪明地利用 AI。**
能主动把 AI 嵌入自己工作、学习和创造流程的人，效率可能提升 10–100 倍；而即便不擅长使用 AI 的人，也可以在高度自动化的经济体系中，通过某种形式的 UBI（或等价安排）过上基本无虞的一生。

### 阶段二：智力远超人类的 AGI ——共存，而非你死我活

如果把时间再往后推，当 AGI 的智力在整体层面远远超过人类时，人类天然会问：我们还能“控制”它吗？我们设定的各种安全框架、对齐机制，真的靠谱吗？

我的判断是：**不要幻想用低一层级的智能，通过规则和框架，完全束缚高一层级的智能。**
我们能设计的所有“安全沙盒”，在理论上都有被更高智能突破的可能。

但这并不自动意味着“人类必然会被消灭”。关键在于：**在进化树上，人类和 AI 所在的“分支”和“需求结构”是不同构的。**

* 我们是碳基生命，建立在有机化学反应链条之上，需要呼吸、进食、睡眠、繁衍，通过主观体验来感受痛苦与快乐。
* 现有技术路线下的 AI 大多是“硅基—电力驱动—数据中心环境”的智能形态，它的生存与优化目标更多与算力、能耗、带宽、网络结构、目标函数有关。

在不少方面，碳基生命反而具有独特优势。例如：

1. **能效极高的通用智能。**
   人脑大约只消耗 20 瓦左右的功率，却能支持语言、抽象思维、艺术创造、空间导航等复杂功能，而当代大模型与 AI 数据中心往往要以千千瓦到兆瓦级的能耗来完成类似任务。([PMC][1])
   正因为此，许多研究正尝试以大脑为原型，发展“类脑计算”“神经形态芯片”，希望复制这种能效与鲁棒性。([Human Brain Project][2])

2. **一体化的感知—行动系统与自修复能力。**
   生物体通过进化形成了高度集成的感知、决策和运动体系，同时具备惊人的自修复、自复制能力。软体机器人与生物混合机器人正试图模仿这种特性，但目前的自愈合材料与系统往往仍然需要人类多次干预，远未达到生物体那种“边受损边修复”的自然水准。([ScienceDirect][3])

3. **对复杂真实环境的适应性与冗余。**
   复杂生态系统中，碳基生命通过种群多样性、生态位分化和多层级食物网来分散风险。相比之下，当前 AI 系统高度集中在少数巨型算力集群之中，对基础设施的依赖度极高，一旦电网、网络或供应链出现系统性故障，人类和 AI 所面临的约束会非常不同。

4. **主观体验与价值建构。**
   人类不仅在“算得更好”，还在不断构造“什么是有意义的”“什么值得去做”。
   在神经科学和计算神经科学中，一个重要观点是：**主观体验可以被看作一种内部优化信号**。

   * 疼痛、愉悦、期待等奖赏相关体验，被建模为强化学习中的“回报信号”，通过多巴胺等神经递质系统调节行为策略。([PMC][4])
   * 在强化学习理论中，存在著名的“奖励假设”：认为智能体的各种目标和目的，都可以视为在某种长期回报函数下的最大化行为，这一观点在 Sutton & Barto 的《Reinforcement Learning: An Introduction》以及 Silver 等人的《Reward is Enough》中得到系统讨论。([Stanford University][5])

   从这个角度看，主观体验本质上是一种进化出的**高效优化机制**：它把极其复杂、多目标的生存和社会问题，浓缩成有限维度的“好 / 不好”“舒适 / 不适”连续感受，用极低的能耗驱动我们调整行为。
   这并不是说机器不能用其他形式实现类似的优化，而是说：**生物这套“感觉—情绪—价值”的体系，在能量与计算资源受限的条件下，极其有效**。

因此，更高等级的 AGI 更像是一种新的“智能物种”，在地球与宇宙中与我们并行演化：
它更适合在算力密集、极端环境中拓展疆界；而我们仍然在日常生活、近地空间、社会与文化结构中扮演独一无二的角色。双方将长期互补，而不是简单的零和博弈。

---

## 二、在确定的不确定中，我们能做什么？

面对这场变革，一个诚实的回答是：**没有人真的知道应该怎么做准备。**

任何声称“已经掌握全部答案”的人，都值得你保持一点警惕。
但有一件事几乎是确定的：**我们必须学习。**

唯一不变的是变化。
我们能做的，是不断学习、不断验证已有经验，而不是固守某一套在旧世界有效、在新世界却日益失效的做事方式。

在 AI 时代，人类不再需要把大量精力花在“努力记住更多知识”这件事上——因为大部分事实性知识的获取成本会无限趋近于零。搜索、问答系统和生成式模型，会以极低成本随时把信息送到你面前。

那么，我们还需要学习什么？

我认为，人类大脑在几个维度上依然具有优势：

* 在极低能耗下进行**模糊计算**和**长程联想**；([PMC][1])
* 在价值、情感、叙事之间建立**跨模态链接**；
* 在不完备、不确定的环境中做出**整体性的判断**。

这意味着，我们的学习重心需要从“记住更多细节”，转向“内化更抽象的结构、理解更广阔的图景”。
当世界的变化加速时，这种结构化的认知能力，会帮助我们更快地应对新局面，也能让我们在面对各种可能的未来结果时更坦然。

---

## 三、学习是一棵生成树

在写这本书的时候，我一直用一个比喻来提醒自己：**学习的过程，就像一棵生成树的生长过程。**

* 根部，是最基本的前提和思维方式；
* 树干，是对世界的总体理解框架；
* 分枝，是各个具体学科、技能和经验；
* 新长出的叶子，是每天获取的零碎知识和信息。

只有根扎得足够深、树干长得足够稳，新的知识才能不断被压缩、吸收，长成这棵树的一部分，而不是一堆堆无法互相连接的碎片。

在这个过程中，AI 可以扮演一个非常重要的角色：
它可以成为我们的“知识压缩与映射器”，帮助我们把新知识压缩成更简洁的结构，并映射到自己已有的知识树上，加速内化。

真正束缚我们的，往往不是信息太少，而是：**新知识和旧知识之间逻辑不自洽。**
当我们试图把一个新的观点塞进一棵早已长歪的知识树时，就会感到巨大的心理阻力和认知混乱。
这也是为什么，渐进式地构建一棵**逻辑自洽**的知识树尤为重要。

---

## 四、这本书想给你的“根”：八个关键节点

因此，本书会从最底层开始，尝试和你一起重建这棵知识树的“根”。在我看来，至少有八个关键节点：

1. **逻辑**
   我们如何从前提推导结论？怎样避免自相矛盾？逻辑是所有理性思考的起点。

2. **逻辑依赖因果**
   真正有意义的推理，离不开因果结构。没有因果，逻辑就会滑向纯形式的游戏，与现实世界脱节。

3. **因果依赖时间**
   因果关系总是嵌在时间之中：原因在前，结果在后。理解时间的单向性，是理解因果的前提。

4. **公理系统：逻辑自洽的思维科学**
   如果我们希望构建一套真正严谨的知识体系，就必须学会用“公理系统”的视角来思考：从一组尽可能简单、清晰的假设出发，在严格的推理规则下演化出整个理论世界。

5. **ZFC 与现代数学的生成**
   以 ZFC 为代表的集合论公理系统展示了一个令人震撼的事实：
   通过极简的存在性假设和推理规则，我们居然可以演化出几乎整个现代数学。
   这不仅是一项数学成就，更是一种关于“如何从简单生成复杂”的范式。

6. **物理世界与数学的同构性**
   令人困惑却极具启发性的现象是：数学在自然科学中“出奇地有效”。物理定律往往可以被极简洁的数学结构表达出来，这提示我们——物理世界与某种深层的数学结构，可能具有某种同构关系。

7. **宇宙的生成论视角：初始量子态 + 最小作用原理**
   如果我们把整个宇宙看作一个由初始量子态出发、在“最小作用原理”约束下演化的巨大系统，那么：

   * 物质结构、天体演化、生命出现，都可以视作这一生成过程中的不同层级；
   * 智能则是耗散系统在这一框架下自组织、涌现出的高度复杂结构，是宇宙“寻找更高效路径”过程中的副产物与参与者。

8. **进化论：涌现复杂性的核心算法**
   进化论不仅是解释生物多样性的理论，也可以被视作一种普适的“搜索与优化算法”：
   在变异与选择的反复迭代中，系统不断逼近在特定环境下更“适应”的结构。
   从生命到文化再到技术演化，背后都可以看到类似的“进化算法”在运行。

本书会沿着这八个节点，带你从逻辑与公理出发，走到数学与物理，再走到生命、意识、社会与 AI——尝试用一条尽可能统一的线索，重新理解我们所处的世界，也重新理解 AGI 时代的来临。

---

## 五、一套面对未来的“坐标系”

这本书不是“如何使用某个 AI 工具”的操作手册，也不是一部“预测未来”的科幻剧本。
它真正想提供的，是一套面对未来的**“坐标系”**：

* 当 AI 持续演化，我们如何不被海量信息和变化节奏淹没？
* 当既有经验失效，我们如何判断哪些观念该坚持，哪些观念该升级？
* 当我们不得不面对“人类不再是宇宙中唯一高级智能”的事实时，我们如何重新理解自己的位置和意义？

AGI 到底会不会在 2030–2035 年之间真正到来，也许并不是最关键的问题。
更关键的是：无论它何时到来，我们是否已经拥有一棵足够坚固、又足够灵活的知识树，一套足够自洽、又能不断更新的世界观。

如果这本书，能在你构建这样一套世界观的过程中，成为一段有用的分枝，甚至帮你在某个时刻“接上”一条更清晰的主干，那它就已经完成了自己的使命。

[1]: https://pmc.ncbi.nlm.nih.gov/articles/PMC8364152/?utm_source=chatgpt.com "Brain power - PMC - PubMed Central - NIH"
[2]: https://www.humanbrainproject.eu/en/follow-hbp/news/2023/09/04/learning-brain-make-ai-more-energy-efficient/?utm_source=chatgpt.com "Learning from the brain to make AI more energy-efficient"
[3]: https://www.sciencedirect.com/science/article/pii/S2589004221010439?utm_source=chatgpt.com "Biology and bioinspiration of soft robotics: Actuation, ..."
[4]: https://pmc.ncbi.nlm.nih.gov/articles/PMC3490621/?utm_source=chatgpt.com "Neural Basis of Reinforcement Learning and Decision Making"
[5]: https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf?utm_source=chatgpt.com "Reinforcement Learning: An Introduction"
